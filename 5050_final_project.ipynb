{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36803a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nba_api\n",
    "from nba_api.stats.endpoints import PlayByPlayV2\n",
    "from nba_api.stats.endpoints import LeagueGameFinder\n",
    "from nba_api.stats.endpoints import BoxScoreTraditionalV3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf068c6",
   "metadata": {},
   "source": [
    "# Identify all OT games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3227362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 2018-19 Regular Season games...\n",
      "Found 67 unique overtime games.\n",
      "Extracting lineups for 67 games...\n",
      "Processing 1/67: 0021801229\n",
      "Processing 2/67: 0021801195\n",
      "Processing 3/67: 0021801201\n",
      "Processing 4/67: 0021801189\n",
      "Processing 5/67: 0021801145\n",
      "Processing 6/67: 0021801132\n",
      "Processing 7/67: 0021801107\n",
      "Processing 8/67: 0021801106\n",
      "Processing 9/67: 0021801080\n",
      "Processing 10/67: 0021801070\n",
      "Processing 11/67: 0021801072\n",
      "Processing 12/67: 0021801069\n",
      "Processing 13/67: 0021801056\n",
      "Processing 14/67: 0021801036\n",
      "Processing 15/67: 0021800988\n",
      "Processing 16/67: 0021800976\n",
      "Processing 17/67: 0021800949\n",
      "Processing 18/67: 0021800928\n",
      "Processing 19/67: 0021800912\n",
      "Processing 20/67: 0021800920\n",
      "Processing 21/67: 0021800881\n",
      "Processing 22/67: 0021800853\n",
      "Processing 23/67: 0021800769\n",
      "Processing 24/67: 0021800760\n",
      "Processing 25/67: 0021800686\n",
      "Processing 26/67: 0021800670\n",
      "Processing 27/67: 0021800657\n",
      "Processing 28/67: 0021800659\n",
      "Processing 29/67: 0021800639\n",
      "Processing 30/67: 0021800619\n",
      "Processing 31/67: 0021800569\n",
      "Processing 32/67: 0021800565\n",
      "Processing 33/67: 0021800552\n",
      "Processing 34/67: 0021800522\n",
      "Processing 35/67: 0021800516\n",
      "Processing 36/67: 0021800505\n",
      "Processing 37/67: 0021800503\n",
      "Processing 38/67: 0021800499\n",
      "Processing 39/67: 0021800495\n",
      "Processing 40/67: 0021800480\n",
      "Processing 41/67: 0021800463\n",
      "Processing 42/67: 0021800421\n",
      "Processing 43/67: 0021800409\n",
      "Processing 44/67: 0021800399\n",
      "Processing 45/67: 0021800371\n",
      "Processing 46/67: 0021800356\n",
      "Processing 47/67: 0021800330\n",
      "Processing 48/67: 0021800323\n",
      "Processing 49/67: 0021800316\n",
      "Processing 50/67: 0021800296\n",
      "Processing 51/67: 0021800266\n",
      "Processing 52/67: 0021800267\n",
      "Processing 53/67: 0021800225\n",
      "Processing 54/67: 0021800216\n",
      "Processing 55/67: 0021800198\n",
      "Processing 56/67: 0021800179\n",
      "Processing 57/67: 0021800175\n",
      "Processing 58/67: 0021800168\n",
      "Processing 59/67: 0021800164\n",
      "Processing 60/67: 0021800143\n",
      "Processing 61/67: 0021800140\n",
      "Processing 62/67: 0021800106\n",
      "Processing 63/67: 0021800104\n",
      "Processing 64/67: 0021800094\n",
      "Processing 65/67: 0021800049\n",
      "Processing 66/67: 0021800046\n",
      "Processing 67/67: 0021800048\n",
      "Success! Saved 'ot_starting_lineups_2018_19.csv'\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "# 1. Get all games from 2018-19 and filter for Overtime\n",
    "def get_ot_games_2018_19():\n",
    "    print(\"Fetching 2018-19 Regular Season games...\")\n",
    "    game_finder = LeagueGameFinder(season_nullable='2018-19', season_type_nullable='Regular Season')\n",
    "    games = game_finder.get_data_frames()[0]\n",
    "    \n",
    "    # Helper to parse minutes\n",
    "    def parse_minutes(min_val):\n",
    "        if pd.isna(min_val): return 0\n",
    "        min_str = str(min_val)\n",
    "        if ':' in min_str:\n",
    "            return int(min_str.split(':')[0])\n",
    "        return int(float(min_str))\n",
    "\n",
    "    games['MIN_CLEAN'] = games['MIN'].apply(parse_minutes)\n",
    "    \n",
    "    # Filter for games longer than 250 minutes (Standard is 240, OT is usually 265)\n",
    "    ot_games_rows = games[games['MIN_CLEAN'] >= 250].copy()\n",
    "    \n",
    "    # Get unique game IDs\n",
    "    unique_ot_ids = ot_games_rows['GAME_ID'].unique().tolist()\n",
    "    \n",
    "    print(f\"Found {len(unique_ot_ids)} unique overtime games.\")\n",
    "    return unique_ot_ids\n",
    "\n",
    "# ...existing code...\n",
    "# ...existing code...\n",
    "# 2. Get starters for OT\n",
    "def get_ot_starting_lineup(game_id):\n",
    "    try:\n",
    "        # Get players in Period 5 (OT1)\n",
    "        box = BoxScoreTraditionalV3(game_id=game_id, start_period=5, end_period=5, range_type=0, timeout=30)\n",
    "        \n",
    "        # MANUAL PARSING: Avoid get_data_frames()\n",
    "        data = box.get_dict()\n",
    "        \n",
    "        if 'boxScoreTraditional' not in data:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        bs = data['boxScoreTraditional']\n",
    "        players_list = []\n",
    "        \n",
    "        # V3 Structure: boxScoreTraditional -> homeTeam/awayTeam -> players\n",
    "        if 'homeTeam' in bs and 'players' in bs['homeTeam']:\n",
    "            for p in bs['homeTeam']['players']:\n",
    "                # Flatten the nested structure\n",
    "                flat_player = {\n",
    "                    'personId': p.get('personId'),\n",
    "                    'firstName': p.get('firstName'),\n",
    "                    'familyName': p.get('familyName'),\n",
    "                    'teamId': bs['homeTeamId'],\n",
    "                    'teamTricode': bs['homeTeam'].get('teamTricode')\n",
    "                }\n",
    "                if 'statistics' in p:\n",
    "                    flat_player.update(p['statistics'])\n",
    "                players_list.append(flat_player)\n",
    "        \n",
    "        if 'awayTeam' in bs and 'players' in bs['awayTeam']:\n",
    "            for p in bs['awayTeam']['players']:\n",
    "                flat_player = {\n",
    "                    'personId': p.get('personId'),\n",
    "                    'firstName': p.get('firstName'),\n",
    "                    'familyName': p.get('familyName'),\n",
    "                    'teamId': bs['awayTeamId'],\n",
    "                    'teamTricode': bs['awayTeam'].get('teamTricode')\n",
    "                }\n",
    "                if 'statistics' in p:\n",
    "                    flat_player.update(p['statistics'])\n",
    "                players_list.append(flat_player)\n",
    "            \n",
    "        if not players_list:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        players_df = pd.DataFrame(players_list)\n",
    "        \n",
    "        # 1. Normalize column names to uppercase\n",
    "        players_df.columns = [c.upper() for c in players_df.columns]\n",
    "        \n",
    "        # 2. Map V3 columns to standard names\n",
    "        rename_map = {\n",
    "            'PERSONID': 'PLAYER_ID',\n",
    "            'TEAMID': 'TEAM_ID',\n",
    "            'TEAMTRICODE': 'TEAM_ABBREVIATION',\n",
    "            'MINUTES': 'MIN'\n",
    "        }\n",
    "        players_df = players_df.rename(columns=rename_map)\n",
    "        \n",
    "        # 3. Handle Player Name\n",
    "        if 'PLAYER_NAME' not in players_df.columns:\n",
    "            if 'FIRSTNAME' in players_df.columns and 'FAMILYNAME' in players_df.columns:\n",
    "                players_df['PLAYER_NAME'] = players_df['FIRSTNAME'] + ' ' + players_df['FAMILYNAME']\n",
    "        \n",
    "        # 4. Add GAME_ID\n",
    "        players_df['GAME_ID'] = game_id\n",
    "        \n",
    "        # 5. Filter for active players (those with minutes > 0)\n",
    "        if 'MIN' not in players_df.columns:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        active_ot_players = players_df[players_df['MIN'].notna()].copy()\n",
    "        \n",
    "        # Clean minutes - remove \"0:00\" entries\n",
    "        if active_ot_players['MIN'].dtype == object:\n",
    "             active_ot_players = active_ot_players[active_ot_players['MIN'].str.contains(r'[1-9]', regex=True)]\n",
    "\n",
    "        if active_ot_players.empty: \n",
    "            return pd.DataFrame()\n",
    "\n",
    "        candidate_ids = set(active_ot_players['PLAYER_ID'].tolist())\n",
    "        \n",
    "        # 6. Try to check substitutions (may fail for old games)\n",
    "        try:\n",
    "            pbp = PlayByPlayV2(game_id=game_id, start_period=5, end_period=5, timeout=30)\n",
    "            pbp_df = pbp.play_by_play.get_data_frame()\n",
    "            \n",
    "            subs = pbp_df[pbp_df['EVENTMSGTYPE'] == 8]\n",
    "            non_starters = set()\n",
    "            \n",
    "            for _, row in subs.iterrows():\n",
    "                if row['PCTIMESTRING'] == '05:00':\n",
    "                    non_starters.add(row['PLAYER1_ID']) \n",
    "                else:\n",
    "                    non_starters.add(row['PLAYER2_ID']) \n",
    "            \n",
    "            starter_ids = candidate_ids - non_starters\n",
    "            starters_df = active_ot_players[active_ot_players['PLAYER_ID'].isin(starter_ids)].copy()\n",
    "        except:\n",
    "            # Fallback: Just return top 5 players by minutes for each team\n",
    "            starters_df = active_ot_players.sort_values('MIN', ascending=False).groupby('TEAM_ID').head(5)\n",
    "        \n",
    "        # Ensure we return standard columns\n",
    "        cols_to_return = ['GAME_ID', 'TEAM_ID', 'TEAM_ABBREVIATION', 'PLAYER_ID', 'PLAYER_NAME']\n",
    "        available_cols = [c for c in cols_to_return if c in starters_df.columns]\n",
    "        \n",
    "        return starters_df[available_cols]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing game {game_id}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "# ...existing code...\n",
    "# --- Execute and Save ---\n",
    "ot_game_ids = get_ot_games_2018_19()\n",
    "all_starters = []\n",
    "\n",
    "print(f\"Extracting lineups for {len(ot_game_ids)} games...\")\n",
    "for i, game_id in enumerate(ot_game_ids):\n",
    "    print(f\"Processing {i+1}/{len(ot_game_ids)}: {game_id}\")\n",
    "    df = get_ot_starting_lineup(game_id)\n",
    "    if not df.empty:\n",
    "        all_starters.append(df)\n",
    "    time.sleep(1.0) # Increased delay to avoid API errors\n",
    "\n",
    "if all_starters:\n",
    "    final_df = pd.concat(all_starters, ignore_index=True)\n",
    "    final_df.to_csv('ot_starting_lineups_2018_19.csv', index=False)\n",
    "    print(\"Success! Saved 'ot_starting_lineups_2018_19.csv'\")\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97245b1",
   "metadata": {},
   "source": [
    "# Map Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fb2d1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_df exists in memory!\n",
      "Shape: (670, 5)\n",
      "      GAME_ID     TEAM_ID TEAM_ABBREVIATION  PLAYER_ID          PLAYER_NAME\n",
      "0  0021801229  1610612746               LAC    1627820       Tyrone Wallace\n",
      "1  0021801229  1610612746               LAC    1628414  Sindarius Thornwell\n",
      "2  0021801229  1610612762               UTA    1628960        Grayson Allen\n",
      "3  0021801229  1610612762               UTA    1627777        Georges Niang\n",
      "4  0021801229  1610612762               UTA    1628513      Naz Mitrou-Long\n",
      "5  0021801229  1610612746               LAC    1627826          Ivica Zubac\n",
      "6  0021801229  1610612746               LAC    1629013        Landry Shamet\n",
      "7  0021801229  1610612762               UTA     202327            Ekpe Udoh\n",
      "8  0021801229  1610612762               UTA     200757      Thabo Sefolosha\n",
      "9  0021801229  1610612746               LAC     203210       JaMychal Green\n",
      "\n",
      "File saved to: C:\\Users\\ariel\\OneDrive\\Documents\\ot_starting_lineups_2018_19.csv\n",
      "Total rows: 670\n",
      "Total unique games: 67\n"
     ]
    }
   ],
   "source": [
    "# Check if we have the data in memory\n",
    "if 'final_df' in locals() or 'final_df' in globals():\n",
    "    print(\"final_df exists in memory!\")\n",
    "    print(f\"Shape: {final_df.shape}\")\n",
    "    print(final_df.head(10))\n",
    "    \n",
    "    # Save to OneDrive Documents\n",
    "    import os\n",
    "    documents_path = r\"C:\\Users\\ariel\\OneDrive\\Documents\"\n",
    "    csv_path = os.path.join(documents_path, 'ot_starting_lineups_2018_19.csv')\n",
    "    final_df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nFile saved to: {csv_path}\")\n",
    "    print(f\"Total rows: {len(final_df)}\")\n",
    "    print(f\"Total unique games: {final_df['GAME_ID'].nunique()}\")\n",
    "else:\n",
    "    print(\"final_df does not exist. The extraction may have failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1005764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned player names:\n",
      "                PLAYER_NAME       PLAYER_NAME_CLEAN\n",
      "559          T.J. McConnell          T.J. McConnell\n",
      "579  Michael Kidd-Gilchrist  Michael Kidd-Gilchrist\n",
      "580             Aron Baynes             Aron Baynes\n",
      "581            Semi Ojeleye            Semi Ojeleye\n",
      "583      Guerschon Yabusele      Guerschon Yabusele\n",
      "589            Jaylen Brown            Jaylen Brown\n",
      "590            Lance Thomas            Lance Thomas\n",
      "595           Allonzo Trier           Allonzo Trier\n",
      "597            Enes Freedom            Enes Freedom\n",
      "598           Cameron Payne           Cameron Payne\n",
      "605         Josh Richardson         Josh Richardson\n",
      "609         Rodney McGruder         Rodney McGruder\n",
      "613             Gary Harris             Gary Harris\n",
      "619      Chandler Hutchison      Chandler Hutchison\n",
      "622       Langston Galloway       Langston Galloway\n",
      "625            Caris LeVert            Caris LeVert\n",
      "630           Davis Bertans           Davis Bertans\n",
      "631        Quincy Pondexter        Quincy Pondexter\n",
      "638        Dennis Smith Jr.        Dennis Smith Jr.\n",
      "648               Ish Smith               Ish Smith\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "# Function to remove accents from text\n",
    "def remove_accents(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    # Normalize to NFD (decomposed form) and filter out combining characters\n",
    "    nfd = unicodedata.normalize('NFD', text)\n",
    "    return ''.join(char for char in nfd if unicodedata.category(char) != 'Mn')\n",
    "\n",
    "# Clean player names in final_df\n",
    "final_df['PLAYER_NAME_CLEAN'] = final_df['PLAYER_NAME'].apply(remove_accents)\n",
    "\n",
    "print(\"Cleaned player names:\")\n",
    "print(final_df[['PLAYER_NAME', 'PLAYER_NAME_CLEAN']].drop_duplicates().tail(20))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "813c4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAPM data loaded!\n",
      "Shape: (529, 10)\n",
      "\n",
      "First few rows:\n",
      "   Unnamed: 0  playerId       playerName  RAPM  RAPM_Rank  RAPM__Def  \\\n",
      "0           0    101106     Andrew Bogut -0.10      280.0      -0.15   \n",
      "1           1    101107  Marvin Williams -0.07      269.0      -0.37   \n",
      "2           2    101108       Chris Paul  1.69       42.0       1.13   \n",
      "3           3    101109   Raymond Felton  0.03      234.0       0.74   \n",
      "4           4    101112    Channing Frye -1.78      503.0      -1.21   \n",
      "\n",
      "   RAPM__Def_Rank  RAPM__Off  RAPM__Off_Rank  RAPM__intercept  \n",
      "0           324.0       0.05           228.0           111.32  \n",
      "1           404.0       0.31           145.0           111.32  \n",
      "2            25.0       0.56            97.0           111.32  \n",
      "3            72.0      -0.71           455.0           111.32  \n",
      "4           514.0      -0.57           431.0           111.32  \n",
      "\n",
      "Column names:\n",
      "['Unnamed: 0', 'playerId', 'playerName', 'RAPM', 'RAPM_Rank', 'RAPM__Def', 'RAPM__Def_Rank', 'RAPM__Off', 'RAPM__Off_Rank', 'RAPM__intercept']\n",
      "\n",
      "Merged data shape: (670, 17)\n",
      "Players with RAPM data: 641/670\n",
      "\n",
      "Sample merged data:\n"
     ]
    }
   ],
   "source": [
    "# Load RAPM data\n",
    "rapm_path = r\"C:\\Users\\ariel\\OneDrive\\Documents\\rapm.csv\"\n",
    "rapm_df = pd.read_csv(rapm_path)\n",
    "\n",
    "print(\"\\nRAPM data loaded!\")\n",
    "print(f\"Shape: {rapm_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(rapm_df.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(rapm_df.columns.tolist())\n",
    "\n",
    "# Clean RAPM player names too\n",
    "rapm_df['playerName_clean'] = rapm_df['playerName'].apply(remove_accents)\n",
    "\n",
    "# Merge the datasets\n",
    "merged_df = final_df.merge(\n",
    "    rapm_df,\n",
    "    left_on='PLAYER_NAME_CLEAN',\n",
    "    right_on='playerName_clean',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nMerged data shape: {merged_df.shape}\")\n",
    "print(f\"Players with RAPM data: {merged_df['playerName'].notna().sum()}/{len(merged_df)}\")\n",
    "print(\"\\nSample merged data:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "253ccac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAPM data loaded!\n",
      "Shape: (529, 10)\n",
      "\n",
      "First few rows:\n",
      "   Unnamed: 0  playerId       playerName  RAPM  RAPM_Rank  RAPM__Def  \\\n",
      "0           0    101106     Andrew Bogut -0.10      280.0      -0.15   \n",
      "1           1    101107  Marvin Williams -0.07      269.0      -0.37   \n",
      "2           2    101108       Chris Paul  1.69       42.0       1.13   \n",
      "3           3    101109   Raymond Felton  0.03      234.0       0.74   \n",
      "4           4    101112    Channing Frye -1.78      503.0      -1.21   \n",
      "\n",
      "   RAPM__Def_Rank  RAPM__Off  RAPM__Off_Rank  RAPM__intercept  \n",
      "0           324.0       0.05           228.0           111.32  \n",
      "1           404.0       0.31           145.0           111.32  \n",
      "2            25.0       0.56            97.0           111.32  \n",
      "3            72.0      -0.71           455.0           111.32  \n",
      "4           514.0      -0.57           431.0           111.32  \n",
      "\n",
      "Column names:\n",
      "['Unnamed: 0', 'playerId', 'playerName', 'RAPM', 'RAPM_Rank', 'RAPM__Def', 'RAPM__Def_Rank', 'RAPM__Off', 'RAPM__Off_Rank', 'RAPM__intercept']\n",
      "\n",
      "Merged data shape: (670, 17)\n",
      "Players with RAPM data: 641/670\n",
      "\n",
      "Sample merged data:\n",
      "           PLAYER_NAME TEAM_ABBREVIATION           playerName  RAPM__Def  \\\n",
      "0       Tyrone Wallace               LAC       Tyrone Wallace       0.35   \n",
      "1  Sindarius Thornwell               LAC  Sindarius Thornwell       0.30   \n",
      "2        Grayson Allen               UTA        Grayson Allen      -1.00   \n",
      "3        Georges Niang               UTA        Georges Niang      -0.91   \n",
      "4      Naz Mitrou-Long               UTA      Naz Mitrou-Long      -0.44   \n",
      "5          Ivica Zubac               LAC          Ivica Zubac       1.14   \n",
      "6        Landry Shamet               LAC        Landry Shamet      -0.71   \n",
      "7            Ekpe Udoh               UTA            Ekpe Udoh      -0.54   \n",
      "8      Thabo Sefolosha               UTA      Thabo Sefolosha       0.95   \n",
      "9       JaMychal Green               LAC       JaMychal Green      -0.81   \n",
      "\n",
      "   RAPM__Off  \n",
      "0       0.12  \n",
      "1      -0.49  \n",
      "2      -0.67  \n",
      "3      -0.05  \n",
      "4       0.06  \n",
      "5      -0.57  \n",
      "6       0.58  \n",
      "7      -0.01  \n",
      "8       0.12  \n",
      "9      -1.28  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load RAPM data\n",
    "rapm_path = r\"C:\\Users\\ariel\\OneDrive\\Documents\\rapm.csv\"\n",
    "rapm_df = pd.read_csv(rapm_path)\n",
    "\n",
    "print(\"\\nRAPM data loaded!\")\n",
    "print(f\"Shape: {rapm_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(rapm_df.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(rapm_df.columns.tolist())\n",
    "\n",
    "# Clean RAPM player names too\n",
    "rapm_df['playerName_clean'] = rapm_df['playerName'].apply(remove_accents)\n",
    "\n",
    "# Merge the datasets\n",
    "merged_df = final_df.merge(\n",
    "    rapm_df,\n",
    "    left_on='PLAYER_NAME_CLEAN',\n",
    "    right_on='playerName_clean',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nMerged data shape: {merged_df.shape}\")\n",
    "print(f\"Players with RAPM data: {merged_df['playerName'].notna().sum()}/{len(merged_df)}\")\n",
    "print(\"\\nSample merged data:\")\n",
    "print(merged_df[['PLAYER_NAME', 'TEAM_ABBREVIATION', 'playerName', 'RAPM__Def', 'RAPM__Off']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "527a8b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching game results...\n",
      "Processing game 1/67: 0021801229\n",
      "Processing game 2/67: 0021801195\n",
      "Processing game 3/67: 0021801201\n",
      "Processing game 4/67: 0021801189\n",
      "Processing game 5/67: 0021801145\n",
      "Processing game 6/67: 0021801132\n",
      "Processing game 7/67: 0021801107\n",
      "Processing game 8/67: 0021801106\n",
      "Processing game 9/67: 0021801080\n",
      "Processing game 10/67: 0021801070\n",
      "Processing game 11/67: 0021801072\n",
      "Processing game 12/67: 0021801069\n",
      "Processing game 13/67: 0021801056\n",
      "Processing game 14/67: 0021801036\n",
      "Processing game 15/67: 0021800988\n",
      "Processing game 16/67: 0021800976\n",
      "Processing game 17/67: 0021800949\n",
      "Processing game 18/67: 0021800928\n",
      "Processing game 19/67: 0021800912\n",
      "Processing game 20/67: 0021800920\n",
      "Processing game 21/67: 0021800881\n",
      "Processing game 22/67: 0021800853\n",
      "Processing game 23/67: 0021800769\n",
      "Processing game 24/67: 0021800760\n",
      "Processing game 25/67: 0021800686\n",
      "Processing game 26/67: 0021800670\n",
      "Processing game 27/67: 0021800657\n",
      "Processing game 28/67: 0021800659\n",
      "Processing game 29/67: 0021800639\n",
      "Processing game 30/67: 0021800619\n",
      "Processing game 31/67: 0021800569\n",
      "Processing game 32/67: 0021800565\n",
      "Processing game 33/67: 0021800552\n",
      "Processing game 34/67: 0021800522\n",
      "Processing game 35/67: 0021800516\n",
      "Processing game 36/67: 0021800505\n",
      "Processing game 37/67: 0021800503\n",
      "Processing game 38/67: 0021800499\n",
      "Processing game 39/67: 0021800495\n",
      "Processing game 40/67: 0021800480\n",
      "Processing game 41/67: 0021800463\n",
      "Processing game 42/67: 0021800421\n",
      "Processing game 43/67: 0021800409\n",
      "Processing game 44/67: 0021800399\n",
      "Processing game 45/67: 0021800371\n",
      "Processing game 46/67: 0021800356\n",
      "Processing game 47/67: 0021800330\n",
      "Processing game 48/67: 0021800323\n",
      "Processing game 49/67: 0021800316\n",
      "Processing game 50/67: 0021800296\n",
      "Processing game 51/67: 0021800266\n",
      "Processing game 52/67: 0021800267\n",
      "Processing game 53/67: 0021800225\n",
      "Processing game 54/67: 0021800216\n",
      "Processing game 55/67: 0021800198\n",
      "Processing game 56/67: 0021800179\n",
      "Processing game 57/67: 0021800175\n",
      "Processing game 58/67: 0021800168\n",
      "Processing game 59/67: 0021800164\n",
      "Processing game 60/67: 0021800143\n",
      "Processing game 61/67: 0021800140\n",
      "Processing game 62/67: 0021800106\n",
      "Processing game 63/67: 0021800104\n",
      "Processing game 64/67: 0021800094\n",
      "Processing game 65/67: 0021800049\n",
      "Processing game 66/67: 0021800046\n",
      "Processing game 67/67: 0021800048\n",
      "\n",
      "Game results collected: 67 games\n",
      "      GAME_ID  HOME_TEAM_ID HOME_TEAM_ABB  HOME_SCORE  AWAY_TEAM_ID  \\\n",
      "0  0021801229    1610612746           LAC         143    1610612762   \n",
      "1  0021801195    1610612761           TOR         117    1610612748   \n",
      "2  0021801201    1610612763           MEM         127    1610612742   \n",
      "3  0021801189    1610612756           PHX         133    1610612740   \n",
      "4  0021801145    1610612737           ATL         136    1610612749   \n",
      "\n",
      "  AWAY_TEAM_ABB  AWAY_SCORE  HOME_WIN  \n",
      "0           UTA         137         1  \n",
      "1           MIA         109         1  \n",
      "2           DAL         129         0  \n",
      "3           NOP         126         1  \n",
      "4           MIL         135         1  \n"
     ]
    }
   ],
   "source": [
    "# Get game results using BoxScoreTraditionalV3\n",
    "def get_game_result_v3(game_id):\n",
    "    \"\"\"Get final score and winner for a game using V3 API\"\"\"\n",
    "    try:\n",
    "        box = BoxScoreTraditionalV3(game_id=game_id, timeout=30)\n",
    "        data = box.get_dict()\n",
    "        \n",
    "        if 'boxScoreTraditional' not in data:\n",
    "            return None\n",
    "        \n",
    "        bs = data['boxScoreTraditional']\n",
    "        \n",
    "        result = {\n",
    "            'GAME_ID': game_id,\n",
    "            'HOME_TEAM_ID': bs.get('homeTeamId'),\n",
    "            'HOME_TEAM_ABB': bs.get('homeTeam', {}).get('teamTricode'),\n",
    "            'HOME_SCORE': bs.get('homeTeam', {}).get('statistics', {}).get('points'),\n",
    "            'AWAY_TEAM_ID': bs.get('awayTeamId'),\n",
    "            'AWAY_TEAM_ABB': bs.get('awayTeam', {}).get('teamTricode'),\n",
    "            'AWAY_SCORE': bs.get('awayTeam', {}).get('statistics', {}).get('points'),\n",
    "        }\n",
    "        \n",
    "        # Determine winner\n",
    "        if result['HOME_SCORE'] and result['AWAY_SCORE']:\n",
    "            result['HOME_WIN'] = 1 if result['HOME_SCORE'] > result['AWAY_SCORE'] else 0\n",
    "        else:\n",
    "            result['HOME_WIN'] = None\n",
    "            \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting result for {game_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get all game results\n",
    "print(\"Fetching game results...\")\n",
    "game_results = []\n",
    "for i, game_id in enumerate(merged_df['GAME_ID'].unique()):\n",
    "    print(f\"Processing game {i+1}/{merged_df['GAME_ID'].nunique()}: {game_id}\")\n",
    "    result = get_game_result_v3(game_id)\n",
    "    if result:\n",
    "        game_results.append(result)\n",
    "    time.sleep(0.6)\n",
    "\n",
    "game_results_df = pd.DataFrame(game_results)\n",
    "print(f\"\\nGame results collected: {len(game_results_df)} games\")\n",
    "print(game_results_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
